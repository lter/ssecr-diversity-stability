---
title: "Jornada_ecotone_data_harmonization"
output: pdf_document
date: "2025-10-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(librarian)
shelf('tidyverse', 'vegan', 'ggpubr', "terra", googlesheets4, googledrive)

```


```{r data sources}
# 1) Rodent abundance and biomass data across grassland-shrubland ecotones at 3 sites in the Jornada Basin, 2004-ongoing
# https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-jrn.210262010.89
# no species info, not used. 

# 2) Spring and Fall plant cover across grassland-shrubland ecotones at 3 sites in the Jornada Basin, 2005-ongoing
# https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-jrn.210262001.11

# 3) Rodent capture data across grassland-shrubland ecotones at 3 sites in the Jornada Basin, 2004-ongoing
# https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-jrn.210262008.141

# this should be a great dataset to study community composition change and their impacts on ecosystem functioning.

# habitat broad: drylands; habitat fine: grassland, ecotone, and shrubland
# plot should be site (3) * habitat (3)
```


```{r rodent data - removel method not used}
library(librarian)
# Install missing packages and load needed libraries
shelf(tidyverse, googlesheets4, googledrive, readxl, FSA)
rm(list=ls())

# a function to calculate abundance data
# use the Zippin removal method to calculate population abundance and biomass. 
estimate_N_biomass <- function(data) {
  weight_per_species <- data %>% group_by(Species_code) %>% summarise(weight = mean(Weight, na.rm=T), .groups = "drop")
  
  counts_wide <- data %>% arrange(Night) %>% distinct(Tag, .keep_all = TRUE) %>%
    group_by(Species_code, Night) %>% summarise(captures = n(), .groups = "drop") %>% 
    pivot_wider(names_from = Night, values_from = captures, values_fill = 0)
  
  # print(names(counts_wide))
  night_missed <- setdiff(c("1", "2", "3", "4"), names(counts_wide))
  # print(night_missed)
  if (length(night_missed) > 0) {
    counts_wide <- counts_wide %>% mutate(!!!setNames(rep(list(0), length(night_missed)), night_missed))
  }
  
  # reorder these cols
  counts_wide <- counts_wide %>% relocate(all_of(c("Species_code", "1", "2", "3", "4")), .before = 1)

  results <- counts_wide %>%
  rowwise() %>%
  mutate(model = list(FSA::removal(c_across(c("1", "2", "3", "4")), method = 'Zippin')),
         abundance = as.numeric(model$est["No"]),
         phat = as.numeric(model$est["p"])) %>%
  select(Species_code, abundance)
  results <- results %>% left_join(weight_per_species, by = "Species_code") %>% 
    mutate(biomass = abundance * weight) %>%
    select(Species_code, abundance, biomass)
  return(results)
}

# Design the workflow
# 1. remove missing species, because these records missed weights sometimes. 
# 2. remove recaptured species
# 3. calculate abundance and biomass for each site-habitat using Zippin removal methods

raw_data <- read.csv('/Users/junnawang/courses/SSECR/data_discovery/Jornada_Basin_LTER/knb-lter-jrn.210262008.141/Ecotone_Rodent_Capture.csv')

# remove species with missing tags
raw_data_valid <- raw_data[raw_data$Tag != ".", ]
raw_data_valid$Weight <- as.numeric(raw_data_valid$Weight)

# testing lines
# data_subset <- raw_data_valid[1:15, c("Night", "Tag", "Species_code", "Weight")]
# estimate_N_biomass(data_subset)

data <- raw_data_valid %>% group_by(Year, Site, Habitat) %>% 
  group_modify(~ {
    est <- estimate_N_biomass(.x[, c("Night", "Tag", "Species_code", "Weight")]) 
    as_tibble(est)
    }) %>%
  ungroup()

# add Species_binomial, Common_name: we only have 16 species. 
species_name <- unique(raw_data_valid[, c("Species_code", "Species_binomial", "Common_name")])
species_name <- species_name %>% mutate(trophic = case_when(Species_binomial %in% c("Peromyscus maniculatus", "Peromyscus leucopus", "Peromyscus eremicus", "Mus musculus") ~ "omnivore", 
                                                            Species_binomial %in% c("Onychomys leucogaster", "Onychomys arenicola") ~ "carnivore",
                                                            TRUE ~ "herbivore")) %>%
  mutate(herbivore = case_when(trophic == "herbivore" ~ 'yes', 
                               trophic == "omnivore" ~ 'o', 
                               trophic == "carnivore" ~ 'no') )

data <- left_join(data, species_name, by = "Species_code") %>% 
  mutate(habitat = case_when(Habitat == 'G' ~ 'grassland', 
                             Habitat == 'E' ~ 'ecotone', 
                             Habitat == 'S' ~ 'shrubland'))

# output data use the right format
data_consumer_out <- data.frame(site="JRN", taxa_type="consumer", ecosystem="terrestrial", habitat_broad='dryland', habitat_fine=data$habitat, biome='temperate', guild='rodent')
####
data_consumer_out$plot  <- paste(data$Site, data_consumer_out$habitat_fine, sep = '_')
data_consumer_out$unique_ID <- paste(data_consumer_out$site, data_consumer_out$plot, sep='_')
####
data_consumer_out$year <- data$Year
# no month and day because frequency is once a year 

data_consumer_out$taxon_name <- data$Species_binomial
data_consumer_out$abundance  <- data$biomass
data_consumer_out$unit_abundance  <- "g"
data_consumer_out$scale_abundance <- "per habitat site"
###
### set the rows without species name as not confident
data_consumer_out$id_confidence <- TRUE
data_consumer_out$herbivore <- data$herbivore
data_consumer_out$trophic <- data$trophic
data_consumer_out$taxon_code <- data$Species_code

write.csv(data_consumer_out, 'harmonized_data/consumer_Jornada.csv', row.names = F)
googledrive::drive_upload(media = file.path("harmonized_data/consumer_Jornada.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1NPNdNCa2RJgTyiQmSZRURHCqVmFLrCR1"))


```


```{r rodent data used}
library(librarian)
# Install missing packages and load needed libraries
shelf(tidyverse, googlesheets4, googledrive, readxl, FSA)
rm(list=ls())

# Design the workflow
# 1. remove missing species, because these records missed weights sometimes. 
# 2. remove recaptured species
# 3. calculate abundance and biomass for each site-habitat using Zippin removal methods

raw_data <- read.csv('/Users/junnawang/courses/SSECR/data_discovery/Jornada_Basin_LTER/knb-lter-jrn.210262008.141/Ecotone_Rodent_Capture.csv')

# remove species with missing tags
raw_data_valid <- raw_data[raw_data$Tag != ".", ]
raw_data_valid$Weight <- as.numeric(raw_data_valid$Weight)

# remove recaptured species during each year site habitat capture
raw_data_valid_1capture <- raw_data_valid %>% group_by(Year, Site, Habitat) %>% 
  distinct(Tag, .keep_all = TRUE) %>% 
  select("Tag", "Species_code", "Weight") %>% 
  ungroup()


data <- raw_data_valid_1capture %>% group_by(Year, Site, Habitat, Species_code) %>% 
  summarise(biomass = sum(Weight, na.rm = T), .groups = 'drop')


# add Species_binomial, Common_name: we only have 16 species. 
species_name <- unique(raw_data_valid[, c("Species_code", "Species_binomial", "Common_name")])
species_name <- species_name %>% mutate(trophic = case_when(Species_binomial %in% c("Peromyscus maniculatus", "Peromyscus leucopus", "Peromyscus eremicus", "Mus musculus") ~ "omnivore", 
                                                            Species_binomial %in% c("Onychomys leucogaster", "Onychomys arenicola") ~ "carnivore",
                                                            TRUE ~ "herbivore")) %>%
  mutate(herbivore = case_when(trophic == "herbivore" ~ 'yes', 
                               trophic == "omnivore" ~ 'o', 
                               trophic == "carnivore" ~ 'no') )

data <- left_join(data, species_name, by = "Species_code") %>% 
  mutate(habitat = case_when(Habitat == 'G' ~ 'grassland', 
                             Habitat == 'E' ~ 'ecotone', 
                             Habitat == 'S' ~ 'shrubland'))

# output data use the right format
data_consumer_out <- data.frame(site="JRN", taxa_type="consumer", ecosystem="terrestrial", habitat_broad='dryland', habitat_fine=data$habitat, biome='temperate', guild='rodent')
####
data_consumer_out$plot  <- paste(data$Site, data_consumer_out$habitat_fine, sep = '_')
data_consumer_out$unique_ID <- paste(data_consumer_out$site, data_consumer_out$plot, sep='_')
####
data_consumer_out$year <- data$Year
# no month and day because frequency is once a year 

data_consumer_out$taxon_name <- data$Species_binomial
data_consumer_out$abundance  <- data$biomass
data_consumer_out$unit_abundance  <- "g"
data_consumer_out$scale_abundance <- "per habitat site"
###
### set the rows without species name as not confident
data_consumer_out$id_confidence <- TRUE
data_consumer_out$herbivore <- data$herbivore
data_consumer_out$trophic <- data$trophic
data_consumer_out$taxon_code <- data$Species_code

write.csv(data_consumer_out, 'harmonized_data/consumer_Jornada.csv', row.names = F)
googledrive::drive_upload(media = file.path("harmonized_data/consumer_Jornada.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1NPNdNCa2RJgTyiQmSZRURHCqVmFLrCR1"))

```


```{r plant cover data}
# Introduction of this dataset
# it has three sites: CDRRC Pasture 3, JER Pasture 12A, JER Pasture 9
# each site with 3 habitats: E (Ecotone), G (grassland), S (Shrubland)
# each habitat has 32 quadrats (two rows and 16 quadrats each row)

# I used plant cover data, not the number of plants
raw_plant_data <- read.csv('/Users/junnawang/courses/SSECR/data_discovery/Jornada_Basin_LTER/knb-lter-jrn.210262001.11/Ecotone_quadrat_plant_cover.csv')

# data in 2005 cannot be used, because fall data is not available
plant_data <- raw_plant_data %>% filter(year != 2005)

# 192 species.
# 
# How to deal with "missing", "Missing value", "unidentified cactus species", "unidentified forb", "unidentified grass", "unidentified plant", "unidentified subshrub"? use filter out these records
plant_data <- plant_data %>% filter(!Species_binomial %in% c("missing", "Missing value", "unidentified cactus species", "unidentified forb", "unidentified grass", "unidentified plant", "unidentified subshrub")) %>% 
  filter(LTER_code != "NONE")
# we filtered 2697 / 148772; 1.8% of data; this should be good. 


# How to deal with quadrats with no vegetation cover?
# The averaging across quadrats was done here. so filter out these records, do the sum and then divided by 32 because each habitat site has 32 quadrats. 
plant_data_plot <- plant_data %>% mutate(plot = paste(site, zone, sep = '_'), cover = as.numeric(cover), 
                                         habitat = case_when(zone == 'G' ~ 'grassland', 
                                                             zone == 'E' ~ 'ecotone', 
                                                             zone == 'S' ~ 'shrubland')) %>%
  group_by(year, season, habitat, plot, Species_binomial, LTER_code) %>%
  summarise(cover.avg = sum(cover, na.rm=T) / 32) %>%
  ungroup()

# average across two seasons
plant_data_plot <- plant_data_plot %>% group_by(year, habitat, plot, Species_binomial, LTER_code) %>% 
  summarise(cover = sum(cover.avg, na.rm=T) / 2) %>%
  ungroup()

plant_data_out <- data.frame(site="JRN", taxa_type="producer", ecosystem="terrestrial", habitat_broad='dryland', habitat_fine=plant_data_plot$habitat, biome='temperate', guild='plant', herbivore=NA, year=plant_data_plot$year)

##
plant_data_out$plot  <- plant_data_plot$plot
plant_data_out$unique_ID <- paste(plant_data_out$site, plant_data_out$plot, sep='_')
plant_data_out$taxon_name <- plant_data_plot$Species_binomial
plant_data_out$abundance <- plant_data_plot$cover
plant_data_out$unit_abundance  <- "%"
plant_data_out$scale_abundance <- "1m2"
plant_data_out$id_confidence <- TRUE
#
plant_data_out$taxon_code <- plant_data_plot$LTER_code

write.csv(plant_data_out, 'harmonized_data/producer_Jornada.csv', row.names = F)
googledrive::drive_upload(media = file.path("harmonized_data/producer_Jornada.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1NPNdNCa2RJgTyiQmSZRURHCqVmFLrCR1"))

```

```{r}
# play with the data
plot_data <- plant_data_plot %>% group_by(plot, year) %>% summarise(total_cover = sum(cover))

ggplot(plot_data, aes(x=year, y=total_cover, col=plot)) +
  geom_point() +
  geom_line()


```

