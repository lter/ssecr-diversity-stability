---
title: "NTL_LTER"
output: pdf_document
date: "2024-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r phytoplankton in trout lake area}
library(tidyverse)
rm(list=ls())
# this website link does not work;
# data_phyto_trout <- read.csv('https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-ntl.238.20&entityid=76505f244b022b902963f9665d30667b')
data_phyto_trout <- read.csv("/Users/junnawang/courses/SSECR/data_discovery/North Temperate Lake LTER/knb-lter-ntl.238.20_Phytoplankton_Trout_Lake_Area/phytoplanktonnl.csv")
# 7 lakes in Allequash, Big Muskellunge, Crystal, Sparkling, and Trout lakes and Crystal Bog, and Trout Bog (two bog lakes)
#
unique(data_phyto_trout$lakeid) 
length(unique(data_phyto_trout$taxa_name))   ### ~200 species
#
data_phyto_year_trout <- data_phyto_trout %>% group_by(lakeid, year4) %>% summarise(num_sample = n_distinct(sampledate))
# ~600 species
ggplot(data_phyto_year_trout, aes(x=year4, y=num_sample, color=lakeid)) +
  geom_point() +
  geom_line()
# CR and SP phytoplankton were sampled in 1984~1993, 2005 and 2006
#
# start to harmonize using data collected in the 12 years
# only use data collected in the three months: 4, 8, and 11; to be consistent among these lakes. 
data_phyto_trout$month <- month(data_phyto_trout$sampledate)
data_phyto_trout2005   <- data_phyto_trout %>% filter(year4 %in% c(1984:1993, 2005:2006)) %>% filter(month %in% c(4, 8, 11)) %>% filter(lakeid %in% c("CR", "SP"))
#
# for the Miscellaneous division, give it a unique taxon name--Miscellaneous
data_phyto_trout2005$taxa_name[data_phyto_trout2005$taxa_name==''] <- data_phyto_trout2005$division[data_phyto_trout2005$taxa_name=='']
#
# check if there is duplicated rows
sum(duplicated(data_phyto_trout2005[,1:7])==TRUE)  # 18 rows
# merge duplicated rows: use the average of them
data_phyto_trout2005 <- data_phyto_trout2005 %>% group_by(lakeid, year4, sampledate, sta, depth_range, division, taxa_name, genus, month) %>% summarise_all(mean)
#
# for each site, we only have one station and one depth, so we can omit sta and depth: nsta=n_distinct(sta), ndepth=n_distinct(depth_range)
# output the data that are needed
# total biomass unit: mg/L; relative total biovolume: %
data_phyto_trout_out <- data.frame(site="NTL_Trout", taxa_type="producer", ecosystem="aquatic", habitat_broad='lake', habitat_fine='lake', biome='temperate', guild='plant', herbivore='no', year = data_phyto_trout2005$year4)
##
# data_phyto_trout_out$year  <- data_phyto_trout2005$year4
data_phyto_trout_out$month <- month(data_phyto_trout2005$sampledate)
data_phyto_trout_out$day   <- day(data_phyto_trout2005$sampledate)
##
data_phyto_trout_out$plot  <- data_phyto_trout2005$lakeid
data_phyto_trout_out$unique_ID <- paste(data_phyto_trout_out$site, data_phyto_trout_out$habitat_fine, data_phyto_trout_out$plot, sep='_')
data_phyto_trout_out$unit_abundance  <- "mg/L"
data_phyto_trout_out$scale_abundance <- "1L"
data_phyto_trout_out$taxon_name   <- data_phyto_trout2005$taxa_name
data_phyto_trout_out$abundance <- data_phyto_trout2005$biomass_conc
#### if biomass_conc = 0.0000, i used biomass_conc = 0.0001
data_phyto_trout_out$abundance[data_phyto_trout_out$abundance==0.0000] <- 0.0001
data_phyto_trout_out$id_confidence <- TRUE
data_phyto_trout_out$id_confidence[data_phyto_trout_out$species=="Miscellaneous"] <- FALSE
####
write.csv(data_phyto_trout_out, 'harmonized_data/phytoplankton_trout_lake_area.csv', row.names = F)
####
googledrive::drive_upload(media = file.path("harmonized_data/phytoplankton_trout_lake_area.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1zzesyCB6l88ZqG7rB5uYpIUUe81LCzOx"))

```



```{r zooplankton trout lake}
library(tidyverse)
rm(list=ls())
##
# data_zoop_trout <- read.csv('https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-ntl.37.38&entityid=3d2b1ab343c670c5117824cbfdaeec12')
data_zoop_trout <- read.csv("/Users/junnawang/courses/SSECR/data_discovery/North Temperate Lake LTER/knb-lter-ntl.37.38_Zooplankton_Trout_Lake_Area/ntl37_v11.csv")

# uniform lakeid
unique(data_zoop_trout$lakeid)  # Bm -> BM; "Tr" -> "TR"
# 
data_zoop_trout$lakeid[data_zoop_trout$lakeid=='Bm'] <- 'BM'
data_zoop_trout$lakeid[data_zoop_trout$lakeid=='Tr'] <- 'TR'

# use "CR" and "SP" only
data_zoop_trout <- data_zoop_trout %>% filter(lakeid %in% c("CR", "SP"))
#
# check if there is duplicated rows
sum(duplicated(data_zoop_trout[, c(1:4, 6)])==TRUE)  # 140 rows; 
sum(duplicated(data_zoop_trout[, c(1:5)])==TRUE)     # no duplication;
# so many species have species code, but have no names or unknown. 
#
data_zoop_trout_year <- data_zoop_trout %>% group_by(lakeid, year4) %>% summarize(nsta=n_distinct(station), num_sample = n_distinct(sample_date))
# reframe(date=unique(sample_date))
# we only have one station for each lake. 
#
ggplot(data_zoop_trout_year, aes(x=year4, y=num_sample, color=lakeid)) +
  geom_point() +
  geom_line()  

#### prepare for output datasets
data_zoop_trout_out <- data.frame(site="NTL_Trout", taxa_type="consumer", ecosystem="aquatic", habitat_broad='lake', habitat_fine='lake', biome='temperate', guild='zooplankton', herbivore='yes', year = data_zoop_trout$year4)
####
data_zoop_trout_out$month <- month(data_zoop_trout$sample_date)
data_zoop_trout_out$day   <- day(data_zoop_trout$sample_date)
####
data_zoop_trout_out$plot  <- data_zoop_trout$lakeid
data_zoop_trout_out$unique_ID <- paste(data_zoop_trout_out$site, data_zoop_trout_out$habitat_fine, data_zoop_trout_out$plot, sep='_')
data_zoop_trout_out$unit_abundance  <- "number/L"
data_zoop_trout_out$scale_abundance <- "1L"
data_zoop_trout_out$taxon_name <- data_zoop_trout$species_name
data_zoop_trout_out$abundance  <- data_zoop_trout$density
data_zoop_trout_out$taxon_code <- data_zoop_trout$species_code
###
### set the rows without species name as not confident
data_zoop_trout_out$id_confidence <- TRUE
data_zoop_trout_out$id_confidence[data_zoop_trout_out$species==''] <- FALSE
###
# ### merge duplicated rows
# data_zoop_trout_out <- data_zoop_trout_out %>% group_by(site, taxa_type, ecosystem, habitat, biome, guild, year, month, day, plot, unique_ID, unit_abundance, scale_abundance, species) %>% summarise(abundance = sum(abundance))

####
write.csv(data_zoop_trout_out, 'harmonized_data/zooplankton_trout_lake_area.csv', row.names = F)
googledrive::drive_upload(media = file.path("harmonized_data/zooplankton_trout_lake_area.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1zzesyCB6l88ZqG7rB5uYpIUUe81LCzOx"))

```


```{r benthic macroinvertebrates, not used because data are from 2011}
library(tidyverse)
rm(list=ls())
###
# data_binvert <- read.csv('https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-ntl.11.38&entityid=64a3def6d4f03ea0ac3e8630b75df453')
data_binvert <- read.csv("/Users/junnawang/courses/SSECR/data_discovery/North Temperate Lake LTER/knb-lter-ntl.11.38_benthic_macroinvertebrates/ntl11_1_v12.csv")

# A: abundant but not counted
# N: Taxon present but not counted
# A and N cannot be taken account of
#
data_binvert_year <- data_binvert %>% group_by(lakeid, site, year4) %>% summarise(num_taxon = n_distinct(taxon_code))
# most data are from 2011, 3 years in the 1980s,
##
# macrophytes are only at 3 lakes (CR, SP, TR), but each lake has different replicates!
unique(data_binvert_year$lakeid)
####
tmp <- data_binvert_year %>% filter(lakeid=='CR')
unique(tmp$year4)
#### CR lake has 5 sites: 27, 43, 6, 9, and GILL; gill likely mean the data collected by gill net. 
#### SP lake has 5 sites: "1",  "19", "21", "24", "GILL"
#### TR lake has 7 sites: "17", "31", "50", "56", "67", "7", "GILL"

#### data wranggle: change 'sp' to 'SP'; important!
#### I have to choose the years: all the sites are measured 
#### CR is measured in these 14 years (maximum): 1982 1985 1987 2011 2012 2013 2014 2015 2016 2017 2018 2019 2022 2023
#### SP is mostly measured in 2011 2012 2014 2015 2016 2017 2018 2019 2022 2023; although some sites with data in the 1980s. 
#### TR is measured in so many years from 1980s, 1990s, 2000s, and 2010s; but I only use the data after 2011 in order to be comparable across different sites. 

#### 
data_binvert$lakeid[data_binvert$lakeid=='sp'] <- 'SP'
# only use the data after 2010; and get the average of multiple replicates
data_binvert2000 <- data_binvert %>% filter(year4 > 2010) 
data_binvert2000_avg <- data_binvert2000 %>% group_by(lakeid, year4, site, taxon_code, description) %>% summarise(abundance=sum(number_indiv) / n_distinct(rep)) %>% filter(abundance > 0)
####
#### present (N) and abundant (A; too many to be counted); data after 2010 does not have this problem;
data_binvert_out <- data.frame(site=data_binvert2000_avg$lakeid, taxa_type="consumer", ecosystem="aquatic", habitat_broad='lake', habitat_fine='lake', biome='temperate', guild='benthic macroinvertebrates', herbivore='unsure')
data_binvert_out$year <- data_binvert2000_avg$year4
data_binvert_out$plot <- data_binvert2000_avg$site
####
data_binvert_out$unique_ID <- paste(data_binvert_out$site, data_binvert_out$habitat_fine, data_binvert_out$plot, sep='_')
####
data_binvert_out$unit_abundance  <- "number/sampler"
data_binvert_out$scale_abundance <- "1_modified_Hester-Dendy_sampler"
data_binvert_out$taxon_name <- data_binvert2000_avg$description
data_binvert_out$abundance  <- data_binvert2000_avg$abundance
####
data_binvert_out$id_confidence <- TRUE
data_binvert_out$id_confidence[data_binvert_out$species==""] <- FALSE
#
write.csv(data_binvert_out, 'harmonized_data/benthic_macroinvertebrates_trout_lake_area.csv', row.names = F)
#
googledrive::drive_upload(media = file.path("harmonized_data/benthic_macroinvertebrates_trout_lake_area.csv"), overwrite = T,
                          path = googledrive::as_id("https://drive.google.com/drive/folders/1zzesyCB6l88ZqG7rB5uYpIUUe81LCzOx"))

###protocols
###The modified Hester-Dendy samplers are constructed as a bolted together stack of ten plastic mesh panels and a plastic scrubbing ball between hardboard end panels. They are placed in the lakes early to mid August, and left for approximately four weeks. Each sampling site consists of three dendy samplers spaced 3 meters apart. Shoreline samplers are set in about one meter of water, deep sites at the deepest part of the lake. The shoreline sets are retrieved by a snorkeler who places the sampler in a container before surfacing to avoid loss of invertebrates due to disturbance, while deep sites are pulled up to the surface from a boat.
###

```


```{r double check if we can use these datasets}
trout_lake_invertebrate <- read.csv('harmonized_data/benthic_macroinvertebrates_trout_lake_area.csv')
unique(trout_lake_invertebrate$year)  # after 2011 
unique(trout_lake_invertebrate$plot)  # only three lakes data, but with multiple plots; CR, SP, TR

#
trout_lake_zooplankton <- read.csv('harmonized_data/zooplankton_trout_lake_area.csv')
sort(unique(trout_lake_zooplankton$year))  # 1981~2022 ; really good long-term data 
unique(trout_lake_zooplankton$site) # 7 lakes: "AL" "BM" "CB" "TB" "CR" "SP" "TR"

#
trout_lake_phytoplankton <- read.csv('harmonized_data/phytoplankton_trout_lake_area.csv')
sort(unique(trout_lake_phytoplankton$year))  # producer data is only in 2005; that is why 
unique(trout_lake_zooplankton$site) # 7 lakes: "AL" "BM" "CB" "TB" "CR" "SP" "TR"

data_binvert <- read.csv('https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-ntl.11.38&entityid=64a3def6d4f03ea0ac3e8630b75df453')


```



